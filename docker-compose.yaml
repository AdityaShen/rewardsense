# RewardSense - Local Airflow Development Environment
# Usage:
#   Initialize: docker-compose up airflow-init
#   Start:      docker-compose up -d
#   Stop:       docker-compose down
#   Reset:      docker-compose down -v (deletes DB data)

x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: Dockerfile.airflow
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__LOAD_EXAMPLES: "False"
    AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres:5432/airflow
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY:-}
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_WEBSERVER_SECRET_KEY:-rewardsense-dev-secret-change-in-prod}
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "True"
    AIRFLOW__CORE__TEST_CONNECTION: Enabled
    # GCP connection - wired up once Story 1.2 is complete
    AIRFLOW_CONN_GOOGLE_CLOUD_DEFAULT: ${AIRFLOW_CONN_GOOGLE_CLOUD_DEFAULT:-}
    GOOGLE_APPLICATION_CREDENTIALS: /opt/airflow/config/service-account-key.json
    # Pipeline config passthrough
    GCP_PROJECT_ID: ${GCP_PROJECT_ID:-rewardsense-prod}
    GCP_BUCKET_NAME: ${GCP_BUCKET_NAME:-rewardsense-dvc-store}
    BIGQUERY_DATASET: ${BIGQUERY_DATASET:-rewardsense_analytics}
  volumes:
    - ./infrastructure/airflow_dags:/opt/airflow/dags
    - ./logs/airflow:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./config:/opt/airflow/config
    - ./src:/opt/airflow/src
  depends_on:
    airflow-postgres:
      condition: service_healthy

services:
  # ----- Airflow-dedicated Postgres -----
  airflow-postgres:
    image: postgres:15
    container_name: rewardsense-airflow-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5433:5432"  # 5433 to avoid conflicts with any local/app postgres
    volumes:
      - airflow-postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ----- Airflow Webserver -----
  airflow-webserver:
    <<: *airflow-common
    container_name: rewardsense-airflow-webserver
    command: airflow webserver
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # ----- Airflow Scheduler -----
  airflow-scheduler:
    <<: *airflow-common
    container_name: rewardsense-airflow-scheduler
    command: airflow scheduler
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname $(hostname) || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # ----- One-time DB init + admin user creation -----
  airflow-init:
    <<: *airflow-common
    container_name: rewardsense-airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate
        airflow users create \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@rewardsense.com
        echo "Airflow initialization complete."
    restart: "no"

volumes:
  airflow-postgres-data:
    name: rewardsense-airflow-pgdata